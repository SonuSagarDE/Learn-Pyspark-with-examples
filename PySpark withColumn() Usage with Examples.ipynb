{"cells":[{"cell_type":"code","source":["data=[('James','','Smith','1991-04-01','M',3000),\n        ('Michael','Rose','','2000-05-19','M',4000),\n  ('Robert','','Williams','1978-09-05','M',4000),\n  ('Maria','Anne','Jones','1967-12-01','F',4000),\n  ('Jen','Mary','Brown','1980-02-17','F',-1)\n    ]\n\ncolumns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\ndf=spark.createDataFrame(data=data,schema=columns)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7ca06fcd-64dd-4a58-9a32-ed8fb842b8f8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["## Change the datatype using with Column\nfrom pyspark.sql.functions import col,cast\ndf.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5468ac27-ce11-4dff-8b1a-88c740c6746b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["## Update the value of existing columms\ndf1=df.withColumn(\"salary\",col(\"salary\")*100)\ndf1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6803480f-4c6c-4194-97f2-a65bfe504aee","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|300000|\n|  Michael|      Rose|        |2000-05-19|     M|400000|\n|   Robert|          |Williams|1978-09-05|     M|400000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|400000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  -100|\n+---------+----------+--------+----------+------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["## Create New column from Exising \ndf2=df.withColumn(\"Salary_copy\",col(\"salary\")*-1)\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"19b6c401-8244-4a6c-ba24-2e8c2341a0d0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----------+--------+----------+------+------+-----------+\n|firstname|middlename|lastname|       dob|gender|salary|Salary_copy|\n+---------+----------+--------+----------+------+------+-----------+\n|    James|          |   Smith|1991-04-01|     M|  3000|      -3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|      -4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|      -4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|      -4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|          1|\n+---------+----------+--------+----------+------+------+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["## Add a New Column\nfrom pyspark.sql.functions import lit\ndf3=df.withColumn(\"data_src\",lit(\"emp\"))\\\n      .withColumn(\"another\",lit(\"emp_an\"))\ndf3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bdb1ebaf-8d96-40bf-a8f5-b5244adab102","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+----------+--------+----------+------+------+--------+-------+\n|firstname|middlename|lastname|       dob|gender|salary|data_src|another|\n+---------+----------+--------+----------+------+------+--------+-------+\n|    James|          |   Smith|1991-04-01|     M|  3000|     emp| emp_an|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|     emp| emp_an|\n|   Robert|          |Williams|1978-09-05|     M|  4000|     emp| emp_an|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|     emp| emp_an|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|     emp| emp_an|\n+---------+----------+--------+----------+------+------+--------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f48e7338-e16b-474a-91a8-73f1951e329f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark withColumn() Usage with Examples","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
